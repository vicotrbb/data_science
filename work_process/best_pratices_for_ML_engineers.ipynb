{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_pratices_for_ML_engineers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/work_process/best_pratices_for_ML_engineers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXJDf46z7TX3"
      },
      "source": [
        "# Importantes dicas para ser um engenheiro de ML melhor\n",
        "\n",
        "Um questionamento constante que tenho quando estou desenvolvendo um novo script para treinar um modelo ou mesmo uma nova API para poder consumi-los, é se oque eu se estou seguindo as boas práticas, criar serviços voltados a ML e IA não são iguais ao desenvolvimento de software convencional, mas isso não quer dizer que não devemos seguir boas práticas e manter esses serviços o melhor possivel.\n",
        "\n",
        "A frente, seguem dicas que podem ajudar a melhorar seu trabalho. A maioria dos topicos são retirados de leituras que realizei e alguns poucos são de minha autoria, referencias seguem abaixo.\n",
        "\n",
        "## Author\n",
        "\n",
        "* Victor Bona - https://www.linkedin.com/in/victorbona/\n",
        "\n",
        "## Referencias\n",
        "\n",
        "* https://medium.com/modern-nlp/10-great-ml-practices-for-python-developers-b089eefc18fc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DV2T-EEkWH"
      },
      "source": [
        "# Apresente o progresso de tarefas importantes e onerosas\n",
        "\n",
        "Acompanhar o progresso de grandes tarefas pode ser uma excelente pratica, visando facilitar o acompanhamento do processo, melhor percepção de métricas e facilitar a percepção de *leaks*.\n",
        "\n",
        "Para esta tarefa, recomenda-se o uso da lib fastprogress, como demonstrado no exemplo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLCEVLo6-hl",
        "outputId": "79ce4c82-783c-457d-8d27-723a368950f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from fastprogress.fastprogress import progress_bar\n",
        "from time import sleep\n",
        "for j in progress_bar(range(100)):\n",
        "  sleep(0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [100/100 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diOwp76GGB1D"
      },
      "source": [
        "# Contabilize tempo de execução\n",
        "\n",
        "Da mesma forma como a dica anterior, esta visa também facilitar o acompanhamento dos processos, poder contabilizar quanto tempo um processo demora para executar por completo, pode ajudar muito e antender onde melhorar no seu pipeline ou identificar possiveis *leaks*.\n",
        "\n",
        "A ideia do exemplo abaixo, é criar um *decorator* para permitir a facil metrificação do tempo de execução dos métodos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vCxY8CGB5i"
      },
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def timing(f):\n",
        "  \"\"\"Decorator for timing functions\n",
        "  Usage:\n",
        "  @timing\n",
        "  def function(a):\n",
        "    pass\n",
        "  \"\"\"\n",
        "\n",
        "  @wraps(f)\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start = time.time()\n",
        "    result = f(*args, **kwargs)\n",
        "    end = time.time()\n",
        "    print('function:%r took: %2.2f sec' % (f.__name__,  end - start))\n",
        "    return result\n",
        "  return wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQeVBspzGneM",
        "outputId": "987e43ec-2dcd-4fd5-f402-e51920b2af58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "@timing\n",
        "def teste():\n",
        "  y = 0\n",
        "  for x in range(1,10000000):\n",
        "    y += x\n",
        "  print(y)\n",
        "\n",
        "teste()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49999995000000\n",
            "function:'teste' took: 0.61 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOGB6YvHdVO"
      },
      "source": [
        "# Sempre tenha formas de evitar disperdicio de recursos\n",
        "\n",
        "Quando vamos treinar um modelo em uma maquina na nuvem, normalmente isso custa muito caro, pricipalmente por que as maquinas utilizadas são de alto desempenho e custam mais caro naturalmente. \n",
        "\n",
        "O problema mesmo é quando o egenheiro que projetou o pipeline acaba esquecendo de checar quando o modelo já esta pronto para desligar a maquina ou pausa-la, ocasionando em gastos desnecessários.\n",
        "\n",
        "Visando evitar esse problema, crie algum método para desligar a maquina depois que terminar e salvar o processo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBSGtgh7HeAI"
      },
      "source": [
        "import os\n",
        "\n",
        "def shutdown(seconds=0):\n",
        "  os.system(f'sudo shutdown -h -t sec {seconds}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3BayxPOkmuV"
      },
      "source": [
        "# Fixe as seeds do seu projeto\n",
        "\n",
        "Uma boa pratica, é fixar as \"seeds\" do seu projeto, para que seja possivel reproduzir seus resultados em outros ambientes. Essas seeds são os valores utilizados como parametro para realizar alguns processos importantes.\n",
        "\n",
        "Normalmente, as seeds são fixadas no topo do seu projeto ou em um método de setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-iekiZEkm7a"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(66)\n",
        "tf.random.set_seed(66)\n",
        "np.random.seed(66)\n",
        "random.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}