{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_pratices_for_ML_engineers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/work_process/best_pratices_for_ML_engineers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXJDf46z7TX3"
      },
      "source": [
        "# Importantes dicas para ser um engenheiro de ML melhor\n",
        "\n",
        "Um questionamento constante que tenho quando estou desenvolvendo um novo script para treinar um modelo ou mesmo uma nova API para poder consumi-los, é se oque eu se estou seguindo as boas práticas, criar serviços voltados a ML e IA não são iguais ao desenvolvimento de software convencional, mas isso não quer dizer que não devemos seguir boas práticas e manter esses serviços o melhor possivel.\n",
        "\n",
        "A frente, seguem dicas que podem ajudar a melhorar seu trabalho. A maioria dos topicos são retirados de leituras que realizei e alguns poucos são de minha autoria, referencias seguem abaixo.\n",
        "\n",
        "## Author\n",
        "\n",
        "* Victor Bona - https://www.linkedin.com/in/victorbona/\n",
        "\n",
        "## Referencias\n",
        "\n",
        "* https://medium.com/modern-nlp/10-great-ml-practices-for-python-developers-b089eefc18fc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DV2T-EEkWH"
      },
      "source": [
        "# Apresente o progresso de tarefas importantes e onerosas\n",
        "\n",
        "Acompanhar o progresso de grandes tarefas pode ser uma excelente pratica, visando facilitar o acompanhamento do processo, melhor percepção de métricas e facilitar a percepção de *leaks*.\n",
        "\n",
        "Para esta tarefa, recomenda-se o uso da lib fastprogress, como demonstrado no exemplo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLCEVLo6-hl",
        "outputId": "79ce4c82-783c-457d-8d27-723a368950f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from fastprogress.fastprogress import progress_bar\n",
        "from time import sleep\n",
        "for j in progress_bar(range(100)):\n",
        "  sleep(0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [100/100 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diOwp76GGB1D"
      },
      "source": [
        "# Contabilize tempo de execução\n",
        "\n",
        "Da mesma forma como a dica anterior, esta visa também facilitar o acompanhamento dos processos, poder contabilizar quanto tempo um processo demora para executar por completo, pode ajudar muito e antender onde melhorar no seu pipeline ou identificar possiveis *leaks*.\n",
        "\n",
        "A ideia do exemplo abaixo, é criar um *decorator* para permitir a facil metrificação do tempo de execução dos métodos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vCxY8CGB5i"
      },
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def timing(f):\n",
        "  \"\"\"Decorator for timing functions\n",
        "  Usage:\n",
        "  @timing\n",
        "  def function(a):\n",
        "    pass\n",
        "  \"\"\"\n",
        "\n",
        "  @wraps(f)\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start = time.time()\n",
        "    result = f(*args, **kwargs)\n",
        "    end = time.time()\n",
        "    print('function:%r took: %2.2f sec' % (f.__name__,  end - start))\n",
        "    return result\n",
        "  return wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQeVBspzGneM",
        "outputId": "987e43ec-2dcd-4fd5-f402-e51920b2af58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "@timing\n",
        "def teste():\n",
        "  y = 0\n",
        "  for x in range(1,10000000):\n",
        "    y += x\n",
        "  print(y)\n",
        "\n",
        "teste()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49999995000000\n",
            "function:'teste' took: 0.61 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOGB6YvHdVO"
      },
      "source": [
        "# Sempre tenha formas de evitar disperdicio de recursos\n",
        "\n",
        "Quando vamos treinar um modelo em uma maquina na nuvem, normalmente isso custa muito caro, pricipalmente por que as maquinas utilizadas são de alto desempenho e custam mais caro naturalmente. \n",
        "\n",
        "O problema mesmo é quando o egenheiro que projetou o pipeline acaba esquecendo de checar quando o modelo já esta pronto para desligar a maquina ou pausa-la, ocasionando em gastos desnecessários.\n",
        "\n",
        "Visando evitar esse problema, crie algum método para desligar a maquina depois que terminar e salvar o processo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBSGtgh7HeAI"
      },
      "source": [
        "import os\n",
        "\n",
        "def shutdown(seconds=0):\n",
        "  os.system(f'sudo shutdown -h -t sec {seconds}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3BayxPOkmuV"
      },
      "source": [
        "# Fixe as seeds do seu projeto\n",
        "\n",
        "Uma boa pratica, é fixar as \"seeds\" do seu projeto, para que seja possivel reproduzir seus resultados em outros ambientes. Essas seeds são os valores utilizados como parametro para realizar alguns processos importantes.\n",
        "\n",
        "Normalmente, as seeds são fixadas no topo do seu projeto ou em um método de setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-iekiZEkm7a"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(66)\n",
        "tf.random.set_seed(66)\n",
        "np.random.seed(66)\n",
        "random.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj3qm4kt68xh"
      },
      "source": [
        "# Crie um aviso visual ou sonoro\n",
        "\n",
        "Uma outra boa prática para caso você esteja utilizando uma maquina local para treinar seu modelo ou executar um payload pesado, é criar um aviso sonoro ou visual para ser avisado quando finalizar o trabalho.\n",
        "\n",
        "Windows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7VgRQjg7iGY"
      },
      "source": [
        "import winsound\n",
        "\n",
        "def make_noise():\n",
        "  duration = 1000  # milliseconds\n",
        "  freq = 440  # Hz\n",
        "  winsound.Beep(freq, duration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM_xg5688DTN"
      },
      "source": [
        "Linux:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEkJ0P-38JXR"
      },
      "source": [
        "!sudo apt install sox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcktDQjb8Exm"
      },
      "source": [
        "import os \n",
        "\n",
        "def make_noise():\n",
        "    '''Make noise after finishing executing a code'''\n",
        "    duration = 1  # seconds\n",
        "    freq = 440  # Hz\n",
        "    os.system('play -nq -t alsa synth {} sine {}'.format(duration, freq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA4Ee92v8LRA"
      },
      "source": [
        "# Receba uma notificação no email\n",
        "\n",
        "Como a dica anterior, esta dica serve para lhe avisar quando alguma tarefa está completa e que esteja sendo executada longe de você, visando evitar o desperdicio de recursos. \n",
        "\n",
        "Para esta solução, irá ser enviado um email avisando da finalização da tarefa e enviar algumas métricas.\n",
        "\n",
        "Lembrando que para usar a biblioteca abaixo, é preciso utilizar um email gmail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdUDgyen8hMH"
      },
      "source": [
        "!pip install knockknock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bn1SADv8kvK"
      },
      "source": [
        "from knockknock import email_sender\n",
        "\n",
        "\n",
        "@email_sender(recipient_emails=[\"youremail@gmail.com\"], sender_email=\"anotheremail@gmail.com\")\n",
        "def main():\n",
        "    even_arr = []\n",
        "    for i in range(10000):\n",
        "        if i%2==0:\n",
        "            even_arr.append(i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzv7jtdItQ1f"
      },
      "source": [
        "# Tenha em mente o uso de memória de seu modelo\n",
        "\n",
        "Um problema que pode acabar sendo recorrente ao se treinar um modelo de ML ou trabalhar com grandes quantidades de dados, é acabar estourando a memória disponivel no sistema, principalmente caso esteja treinando um modelo de NLP.\n",
        "\n",
        "Para estes casos, pode ser interessante ter em mente a quantidade de memória que os objetos estão utilizando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Ssy5g5tQ75"
      },
      "source": [
        "from collections import Mapping, Container\n",
        "from sys import getsizeof\n",
        " \n",
        "def deep_getsizeof(o, ids):\n",
        "    \"\"\"\n",
        "      Return memory size in MB\n",
        "    \"\"\"\n",
        "    d = deep_getsizeof\n",
        "    if id(o) in ids:\n",
        "        return 0\n",
        " \n",
        "    r = getsizeof(o)\n",
        "    ids.add(id(o))\n",
        " \n",
        "    if isinstance(o, str):\n",
        "        return r / 1048576\n",
        " \n",
        "    if isinstance(o, Mapping):\n",
        "        return (r + sum(d(k, ids) + d(v, ids) for k, v in o.iteritems())) / 1048576\n",
        " \n",
        "    if isinstance(o, Container):\n",
        "        return (r + sum(d(x, ids) for x in o)) / 1048576\n",
        "    \n",
        "    return r / 1048576"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}