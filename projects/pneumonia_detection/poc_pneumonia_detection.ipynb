{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poc_pneumonia_detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/vicotrbb/machine_learning/blob/master/projects/pneumonia_detection/poc_pneumonia_detection.ipynb",
      "authorship_tag": "ABX9TyPzXErPTWv25UBtHcs3jhsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/projects/pneumonia_detection/poc_pneumonia_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUjO4tfqbVI_",
        "colab_type": "text"
      },
      "source": [
        "# Implementação de um classificar de CV para detecção de pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LuprjKDbRus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCBDsI9gHIK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3aed72a3-3aac-4e20-9b1d-e90baa8f6f63"
      },
      "source": [
        "!ls 'drive/My Drive/train'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NORMAL\tPNEUMONIA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnOhCc6CGb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unzip_data(datadir):\n",
        "  with ZipFile(datadir, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir.replace('zip', ''))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlQ72e9CcPN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(datadir, img_size=28):\n",
        "\tfile_list = []\n",
        "\tclass_list = []\n",
        "\tx = []\n",
        "\ty = []\n",
        "\tdata = []\n",
        "\terror = False\n",
        "\tcategories = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "\tfor category in categories: \n",
        "\t\tpath = os.path.join(datadir, category)\n",
        "\t\tclass_index = categories.index(category)\n",
        "\t\tfor img in os.listdir(path):\n",
        "\t\t\ttry:\n",
        "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\t\t\t\tnew_array = cv2.resize(img_array, (img_size, img_size))\n",
        "\t\t\t\tdata.append([new_array, class_index])\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\terror = True\n",
        "\t\t\t\tpass\n",
        "\n",
        "\trandom.shuffle(data)\n",
        "\n",
        "\tfor features, label in data:\n",
        "\t\tx.append(features)\n",
        "\t\ty.append(label)\n",
        "\n",
        "\tx = np.array(x).reshape(-1, img_size, img_size, 1)\n",
        "\tif error:\n",
        "\t\tprint('Erro ao processar algums imagens')\n",
        "\telse:\n",
        "\t\tprint('Imagens processadas com sucesso')\n",
        "\treturn x, y\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyLj3nW3cRlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Pneumonia:\n",
        "\n",
        "\tdef __init__(self, train_dir, test_dir):\n",
        "\t\tself.model = Sequential()\n",
        "\t\tself.img_size = 28\n",
        "\t\tself.categories = ['NORMAL', 'PNEUMONIA']\n",
        "\t\tself.x_train, self.y_train = prepare_data(train_dir)\n",
        "\t\tself.x_test, self.y_test = prepare_data(test_dir)\n",
        "\n",
        "\n",
        "\tdef create_train_model(self):\n",
        "\t\tself.model = Sequential()\n",
        "\t\tself.x_train /= 255\n",
        "\n",
        "\t\t# convolutional layers\n",
        "\t\tself.model.add(Conv2D(32, (3, 3), input_shape = x.shape[1:]))\n",
        "\t\tself.model.add(Activation(\"relu\"))\n",
        "\t\tself.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\t\tself.model.add(Conv2D(64, (3, 3)))\n",
        "\t\tself.model.add(Activation(\"relu\"))\n",
        "\t\tself.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\t\tself.model.add(Conv2D(64, (3, 3)))\n",
        "\t\tself.model.add(Activation(\"relu\"))\n",
        "\t\tself.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\t\tself.model.add(Dropout(0.25))\n",
        "\n",
        "\t\t# hidden layers\n",
        "\t\tself.model.add(Flatten())\n",
        "\t\tself.model.add(Dense(128))\n",
        "\t\tself.model.add(Activation(\"relu\"))\n",
        "\n",
        "\t\tself.model.add(Dense(128))\n",
        "\t\tself.model.add(Activation(\"relu\"))\n",
        "\n",
        "\t\t# output layer\n",
        "\t\tself.model.add(Dense(2))\n",
        "\t\tself.model.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# Compile\n",
        "\t\tself.model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "\t\t\t\toptimizer=\"adam\",\n",
        "\t\t\t\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\t\tself.model.fit(self.x_train, self.y_test, batch_size=32, epochs=40, validation_split=0.1,\n",
        "\t\t\tverbose=1, validation_data=(self.x_test, self.y_test))\n",
        "\n",
        "\t\treturn self\n",
        "\n",
        "\n",
        "\tdef predict_image(self, file):\n",
        "\t\timg_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "\t\tnew_array = cv2.resize(img_array, (self.img_size, self.img_size))\n",
        "\t\timg = new_array.reshape(-1, self.img_size, self.img_size, 1)\n",
        "\t\tprediction = model.predict([img])\n",
        "\t\tprediction = list(prediction[0])\n",
        "\t\tprint(self.categories[prediction.index(max(prediction))])\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok5u-1SOEEAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Pneumonia('drive/My Drive/train', 'drive/My Drive/chest_xray_lite_dataset/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX0xnva2T7FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = model.x_train\n",
        "y_train = model.y_train\n",
        "x_test = model.x_test\n",
        "y_test = model.y_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il0pPU_uUh6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train / 255"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAtl9of1UKaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "1c4e148d-800f-4ea3-b6b6-cd0712bee227"
      },
      "source": [
        "ml_model = Sequential()\n",
        "\n",
        "\t\t# convolutional layers\n",
        "ml_model.add(Conv2D(32, (3, 3), input_shape = x_train.shape[1:]))\n",
        "ml_model.add(Activation(\"relu\"))\n",
        "ml_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "ml_model.add(Conv2D(64, (3, 3)))\n",
        "ml_model.add(Activation(\"relu\"))\n",
        "ml_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "ml_model.add(Conv2D(64, (3, 3)))\n",
        "ml_model.add(Activation(\"relu\"))\n",
        "ml_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "ml_model.add(Dropout(0.25))\n",
        "\n",
        "\t\t# hidden layers\n",
        "ml_model.add(Flatten())\n",
        "ml_model.add(Dense(128))\n",
        "ml_model.add(Activation(\"relu\"))\n",
        "\n",
        "ml_model.add(Dense(128))\n",
        "ml_model.add(Activation(\"relu\"))\n",
        "\n",
        "\t\t# output layer\n",
        "ml_model.add(Dense(2))\n",
        "ml_model.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# Compile\n",
        "ml_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "      optimizer=\"adam\",\n",
        "      metrics=[\"accuracy\"])\n",
        "\n",
        "ml_model.fit(x_train, y_test, batch_size=32, epochs=40, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d5809af86290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       metrics=[\"accuracy\"])\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 971\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    972\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbKIwtDpUvZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}