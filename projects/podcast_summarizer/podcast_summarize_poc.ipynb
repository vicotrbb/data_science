{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "podcast_summarize_poc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJ1bm9KMWeUs/tBnj1UdmV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/projects/podcast_summarizer/podcast_summarize_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1_XtG9-hhqK"
      },
      "source": [
        "# Alternativa utilizando textRank\n",
        "\n",
        "Esta alternativa utiliza o método de classificação textual textRank, método esse que não leva em consideração dados novos nem antigos, mas, pode trabalhar com qualquer peça de texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fTg6CsvkPaZ",
        "outputId": "42becc89-d16d-4b0e-fe49-00c826f09aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRmpgAHbg2eQ"
      },
      "source": [
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        " \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2:\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faVAQbC6jRIy",
        "outputId": "43654f03-0a1b-4e2c-8d55-f282aabd2ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "generate_summary( \"texto.txt\", 2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computational systems operating in the real world are exposed to continuous streams of information and thus are required to learn and remember multiple tasks from dynamic data distributions\n",
            "For instance, an autonomous agent interacting with the environment is required to learn from its own experiences and must be capable of progressively acquiring, fine-tuning, and transferring knowledge over long time spans\n",
            "The ability to continually learn over time by accommodating new knowledge while retaining previously learned experiences is referred to as continual or lifelong learning\n",
            "Such a continuous learning task has represented a long-standing challenge for machine learning and neural networks and, consequently, for the development of artificial intelligence (AI) systems (Hassabis et al., 2017, Thrun and Mitchell, 1995).\n",
            "\n",
            "Indexes of top ranked_sentence order are  [(0.41720694653414675, ['For', 'instance,', 'an', 'autonomous', 'agent', 'interacting', 'with', 'the', 'environment', 'is', 'required', 'to', 'learn', 'from', 'its', 'own', 'experiences', 'and', 'must', 'be', 'capable', 'of', 'progressively', 'acquiring,', 'fine-tuning,', 'and', 'transferring', 'knowledge', 'over', 'long', 'time', 'spans']), (0.36038969642050117, ['The', 'ability', 'to', 'continually', 'learn', 'over', 'time', 'by', 'accommodating', 'new', 'knowledge', 'while', 'retaining', 'previously', 'learned', 'experiences', 'is', 'referred', 'to', 'as', 'continual', 'or', 'lifelong', 'learning']), (0.22240335704535186, ['Computational', 'systems', 'operating', 'in', 'the', 'real', 'world', 'are', 'exposed', 'to', 'continuous', 'streams', 'of', 'information', 'and', 'thus', 'are', 'required', 'to', 'learn', 'and', 'remember', 'multiple', 'tasks', 'from', 'dynamic', 'data', 'distributions'])]\n",
            "Summarize Text: \n",
            " For instance, an autonomous agent interacting with the environment is required to learn from its own experiences and must be capable of progressively acquiring, fine-tuning, and transferring knowledge over long time spans. The ability to continually learn over time by accommodating new knowledge while retaining previously learned experiences is referred to as continual or lifelong learning\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}