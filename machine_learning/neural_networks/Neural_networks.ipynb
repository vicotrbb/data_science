{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/neural_networks/Neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNIBHFAQ9LCM"
      },
      "source": [
        "# Neural networks\n",
        "\n",
        "### Observações\n",
        "\n",
        "* **Nenhum(a)** dos gifs/imagens utilizadas aqui são de minha autoria.\n",
        "\n",
        "### Referencias\n",
        "\n",
        "* https://matheusfacure.github.io/2017/07/12/activ-func/#sig\n",
        "* https://iamtrask.github.io/2015/07/12/basic-python-network/\n",
        "* https://en.wikipedia.org/wiki/Sigmoid_function#Applications\n",
        "* https://nextjournal.com/gkoehler/machine-translation-seq2seq-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC_MAzUSxauL"
      },
      "source": [
        "## Oque é uma rede neural\n",
        "\n",
        "Redes neurais são um sistema de computação inspiradas por redes neurais biologicas que formam o cerebro de seres vivos. Estes sistemas são capazes de \"aprender\" a efetuar tarefas, geralmente sem a necessidade de programar as rotinas das tarefas previamente.\n",
        "\n",
        "Um rede neural é composta por 3 tipos de camadas:\n",
        "\n",
        "* **Camada de entrada** -> A camada de entrada é responsavel por realizar o input de informações;\n",
        "\n",
        "* **Camada oculta** -> É a camada intermediaria entre a de entrada e de saída e é responsavel por performar toda a computação(pode haver mais de uma);\n",
        "\n",
        "* **Camada de saída** -> A camada de saída é responsavel por realizar o output da informação.\n",
        "\n",
        "<img src='https://miro.medium.com/max/500/1*3fA77_mLNiJTSgZFhYnU0Q.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zP951Bp19Y"
      },
      "source": [
        "## Principais aplicações de uma rede neural\n",
        "\n",
        "TO-DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sp63Cv2UfC9"
      },
      "source": [
        "# Camadas de uma rede neural\n",
        "\n",
        "TO-DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2K_orlZ-vH1"
      },
      "source": [
        "# Funções de ativação\n",
        "\n",
        "As funções de ativação tem a responsabilidade de introduzir valores não lineares ao modelo de uma rede neural, habilitando a rede a trabalhar com valores desconhecidos, além das relações lineares entre as variaveis dependentes e independentes.\n",
        "\n",
        "Para um exemplo prático, vejamos o seguinte modelo de uma rede neural de duas camadas(os vieses foram omitidos):\n",
        "\n",
        ">$ y = \\phi(\\phi(\\pmb{X}\\pmb{W_1})\\pmb{W_2})\\pmb{w} $\n",
        "\n",
        "Onde:\n",
        "* $\\pmb{X}$ = Matriz de dados\n",
        "* $\\pmb{W_1}$ = Pesos das camadas oculta\n",
        "* $\\pmb{w}$ = Pesos da camada de saida\n",
        "* $\\phi$ = função de ativação/função não linear\n",
        "\n",
        "Note que caso nós retiremos as funções não lineares do modelo, temos o seguinte resultado:\n",
        "\n",
        ">$ y = \\pmb{X}\\pmb{W_1}\\pmb{W_2}\\pmb{w} $\n",
        "\n",
        "Note que se levarmos em consideração que $ \\pmb{W_1}\\pmb{W_2}\\pmb{w} $ é $\\pmb{u}$, teremos o seguinte resultado:\n",
        "\n",
        ">$ y = \\pmb{X}\\pmb{u} $\n",
        "\n",
        "Este resultado é exatamente um regressão linear, de forma que essa rede neural sem a função de ativação/função não linear, estára sujeita as mesmas restrições dos modelos lineares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxz7-54zbf2w"
      },
      "source": [
        "# Principais tipos de funções de ativação\n",
        "\n",
        "<img src=https://mlfromscratch.com/content/images/2019/12/activation-functions.gif>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOcHlELCJsuP"
      },
      "source": [
        "## Função sigmoide\n",
        "---\n",
        "A **função sigmoide** é uma função usada amplamente na matemárica ecomica e computacional, é chamada dessa forma por sua caracteristica grafica em forma de \"S\", chamada de curva de sigmoide. A função sigmoide é utilizada para a criação e transformação de componentes matematicos não lineares.\n",
        "\n",
        "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1280px-Logistic-curve.svg.png width=\"500\">\n",
        "\n",
        "\n",
        "### Definição da função sigmoide\n",
        "\n",
        ">$ \\sigma(x)=\\frac{1}{1+e^x} $\n",
        "\n",
        ">onde: $ e = 2.718 $, constante de euler\n",
        "\n",
        "Sua derivada:\n",
        "\n",
        "> $ \\sigma'(x)=\\sigma(x)(1-\\sigma(x)) $\n",
        "\n",
        "No caso do primeiro algoritmo de exemplo, a função sigmoide está sendo utilizada para converter os valores em probabilidades. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMRs27bxRqS"
      },
      "source": [
        "## E como fica o código de uma função sigmoide?\n",
        "\n",
        "No código utilizamos o método numpy.exp, este método realiza uma exponenciação da constante de Euler pelo parametro passado pelo método\n",
        "\n",
        "* $ euler = 2.718 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkGNIZpNxWsv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7hFEkFIxY3q",
        "outputId": "25c3edfb-667f-4651-c4fc-db79c4960f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "mmatrix = np.array([[1,2,3],[4,0,6]])\n",
        "print('Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação ReLu: \\n', sigmoid(mmatrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação ReLu: \n",
            " [[0.73105858 0.88079708 0.95257413]\n",
            " [0.98201379 0.5        0.99752738]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tSmVutuboa3"
      },
      "source": [
        "## ReLu \n",
        "---\n",
        "A ativação linear retificada é extremamente semelhante a função identidade, sendo diferente apenas que a ReLu produz zero em metade de seu dominio e como consequencia, as derivadas se mantêm grandes enquanto a unidade estiver ativa.\n",
        "\n",
        "<img src=https://matheusfacure.github.io/img/tutorial/activations/RELU.png width=\"500\">\n",
        "\n",
        "A definição da função ReLu é a seguinte:\n",
        "\n",
        "> $ ReLU(x) = max(0,x) $\n",
        "\n",
        "E sua derivada:\n",
        "\n",
        "> $ ReLU'(x)= \\begin{cases}\n",
        "    \t1, & \\text{se } x\\ge 0\\\\\n",
        "    \t0, & \\text{se } x\\leq 0\n",
        "\t    \\end{cases} $\n",
        "\n",
        "Note que as derivadas não são apenas grandes, mas também estáveis, sendo 1, quando $ x>0 $ e 0 quando $ x<0 $. Note tambem que a segunda derivada é zero em todo o domínio.\n",
        "\n",
        "A ativação ReLu é muito mais eficiente que a ativação sigmoidal por exemplo, contribuindo para popular ainda mais o deep learning e mostrando como algo simples pode ser poderoso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qm10xinbsYE"
      },
      "source": [
        "## E como fica o código de uma função ReLu?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5hpD_k9mHo5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fq0ltmMmHpH",
        "outputId": "a94150c1-2169-421c-855f-083b9972509a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "mmatrix = np.array([[1,2,3],[4,0,6]])\n",
        "print('Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação ReLu: \\n', relu(mmatrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação ReLu: \n",
            " [[1 2 3]\n",
            " [4 0 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyP-opkoe8M"
      },
      "source": [
        "## Softmax\n",
        "---\n",
        "A função softmax é utilizada para modelos de predição de multiplas classes principalmente. A função produz saidas entre 0 e 1, sendo que a soma das saidas em modelos de classificação de classes, sera sempre 1.\n",
        "\n",
        "A definição da função Softmax é a seguinte:\n",
        "\n",
        "> $ f(x) = \\frac{\\exp(x_i)}{\\sum \\exp(x_i))} $\n",
        "\n",
        "A principal diferença entre uma função sigmoide e uma função softmax é seu objetivo de uso, enquanto a função sigmoide é custumeiramente utilizada pra classificação binaria a função softmax é utilizada para classificações multiplas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7jakmXgofea"
      },
      "source": [
        "## E como fica o código de uma função Softmax?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V63GfvSXofkj"
      },
      "source": [
        "def softmax(X):\n",
        "    expo = np.exp(X)\n",
        "    expo_sum = np.sum(np.exp(X))\n",
        "    return expo/expo_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjJ2l_pIsUtc",
        "outputId": "28bc302f-7a69-4e50-a955-edf65c8f6ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "mmatrix = np.array([[1,2,3],[4,0,6]])\n",
        "print('Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação \\\n",
        "ReLu: \\n', softmax(mmatrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor da matriz [[1,2,3],[4,0,6] ao passar por uma função de ativação ReLu: \n",
            " [[0.00555636 0.01510375 0.04105626]\n",
            " [0.11160249 0.00204407 0.82463706]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkirQkltsilb",
        "outputId": "08890b6d-956e-471b-fc84-cf550dbeebef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = softmax(mmatrix)\n",
        "print('Prova de que a soma dos valores de saida da função sempre será 1: ',\n",
        "      np.sum(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prova de que a soma dos valores de saida da função sempre será 1:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHiFLVBotjoN"
      },
      "source": [
        "## Principais casos de uso para cada função\n",
        "\n",
        "* Softmax -> Classificação multipla\n",
        "* Sigmoide -> Classificação binaria\n",
        "* ReLu -> Redes neurais convolucionais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tYcubs5UXAk"
      },
      "source": [
        "# Bias/Viés\n",
        "\n",
        "Um Bias/Viés represeta uma variação fixa no calculo de alguma coisa, no caso de redes neurais, utilizamos um valor de bias durante o calculo dos neuronios.\n",
        "\n",
        "Exemplo: Ao se pesar em uma balança convencional, o valor nunca sera 100% preciso, pois, existe o peso dos itens que estão no seu corpo(roupas, relogio e etc), esse valor dos itens é uma variancia fixa e é chamado de Bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTihzlgxe1B"
      },
      "source": [
        "# Funcionamento de uma rede neural\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R5D9wP6Cs6_"
      },
      "source": [
        "## Neuronios\n",
        "---\n",
        "Os neuronios são a unidade mais basica de uma rede neural, cada RN pode ter um numero diferente de neuronios com funcionamentos diferentes, mas basicamente, os neuronios recebem um dado, processam ele e devolvem outro dado processado. O processo realizado dentro de cada neuronio é parte crucial para definir o funcionamento das redes neurais.\n",
        "\n",
        "<img src=https://victorzhou.com/a74a19dc0599aae11df7493c718abaf9/perceptron.svg width=\"350\">\n",
        "\n",
        "O exemplo acima representa um neuronio de duas entradas, o processo que está aconcendo dentro dele pode ser definido como o seguinte:\n",
        "\n",
        "Primeiro, cada entrada é multiplicada por um peso:\n",
        "\n",
        "* $ x_1 = x_1 * w_1 $\n",
        "* $ x_2 = x_2 * w_2 $\n",
        "\n",
        "Segundo, o resusltado das entradas multiplicadas pelo peso são somadas a um bias/viés.\n",
        "\n",
        "* $ \\alpha = x_1 + x_2 + b $\n",
        "\n",
        "Terceiro, o resultado passa por uma função de ativação/não linearidade(Explicada a diante):\n",
        "\n",
        "* $ y = f(\\alpha) $\n",
        "\n",
        "No final, a seguinte equação define os neuronios:\n",
        "\n",
        "* $ y = f(x_1 * w_1 + x_2 * w_2 + b) $\n",
        "\n",
        "Para melhor entendimento, segue o exemplo:\n",
        "\n",
        "Parametros:\n",
        "* $ w_1 = 0, w_2 = 1 $\n",
        "* $ b = 4 $\n",
        "* $ f() = \\frac{1}{1+e^x} $ (sigma function)\n",
        "\n",
        "Entradas:\n",
        "* $ x_1 = 2, x_2 = 3 $\n",
        "\n",
        "Ex:\n",
        "\n",
        "* $ y = f(2 * 0 + 3 * 1 + 4) $\n",
        "* $ y = f(7) $\n",
        "* $ y \\approx 0,999 $\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yndJRS2pw32b"
      },
      "source": [
        "## Como codar um neuronio?\n",
        "\n",
        "Basicamente, o código de um neuronio compreende todos os processos matematicos que aquele neuronio foi designado pra fazer.\n",
        "\n",
        "Segue exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjLdNg7uxKHm"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7k5cPBzxLiu"
      },
      "source": [
        "class Neuron:\n",
        "\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuOkfYxty-fk",
        "outputId": "9bb820e6-7acf-4106-a7fb-f8a8cee34fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "neuron = Neuron(np.array([0, 2]), 4)\n",
        "print('Valor das entradas 2 e 3 depois do processamento no neuronio: ')\n",
        "print(neuron.feedforward(np.array([2,3])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor das entradas 2 e 3 depois do processamento no neuronio: \n",
            "0.9999546021312976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNqqzdXGwuZi"
      },
      "source": [
        "## Relacionamento entre neuronios\n",
        "\n",
        "Como mencionado anteriormente, uma rede neural nada mais é do que um conjunto de neuronios agrupados e trabalhando em conjunto, onde a saida de um, é a entrada de outro.\n",
        "\n",
        "<img src='https://miro.medium.com/max/3000/1*BIpRgx5FsEMhr1k2EqBKFg.gif' width=\"500\">\n",
        "\n",
        "Como pode ser observado no exemplo a cima, cada neuronio comunica-se com todos os outros na proxima camada, enviando seu output para cada um deles.\n",
        "\n",
        "A estrutura de uma rede neural pode seguir diversos tipos de arquiteturas, contudo, normalmente é melhor representada e construida em cima de um grafo.\n",
        "\n",
        "Os diversos tipos de relacionamentos entre os neuronios de uma rede definem que tipo de rede ela se dará."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-oepx--UmL7"
      },
      "source": [
        "## Como codar um relacionamento entre os neuronios para formar uma rede \"Feedforward\"\n",
        "\n",
        "Lembrando que redes neurais do tipo Feedforward não formam um ciclo, sendo o mais simples tipo de rede neural.\n",
        "\n",
        "Vamos então criar uma rede neural com 3 entradas, uma camada oculta com 3 neuronios e 1 neuronio de saída. Assumindo as seguintes variaveis:\n",
        "\n",
        "* $\\pmb{w_n}$ = [1, 0]\n",
        "* $\\pmb{x_n}$ = [2, 3]\n",
        "* $\\pmb{b}$ = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLbXdLIPS3KU",
        "outputId": "257a95c4-767f-4c5c-822b-fb8b9e49f76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class FeedforwardNetwork:\n",
        "\n",
        "  def __init__(self):\n",
        "    weights = np.array([1, 0])\n",
        "    bias = 0\n",
        "\n",
        "    self.n1 = Neuron(weights, bias)\n",
        "    self.n2 = Neuron(weights, bias)\n",
        "    self.o1 = Neuron(weights, bias)\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    out_n1 = self.n1.feedforward(x)\n",
        "    out_n2 = self.n2.feedforward(x)\n",
        "    out_o1 = self.o1.feedforward(np.array([out_n1, out_n2]))\n",
        "\n",
        "    return out_o1\n",
        "\n",
        "network = FeedforwardNetwork()\n",
        "x = np.array([2, 3])\n",
        "print(network.feedforward(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7069873680001046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZHOZ1ADVR_U"
      },
      "source": [
        "# Avaliando uma rede neural\n",
        "\n",
        "Avaliar uma rede neural tem como principais objetivos entender o quão bom a rede está se comportando e ser capaz de quantificar o quanto as alterações que realizamos nos dados e no modelo afetam sua acuracia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gzvn4GLV6qW"
      },
      "source": [
        "## Loss - Perda\n",
        "\n",
        "A métrica de Loss representa basicamente o quão bem um modelo foi predizendo um exemplo em especial, este dado é utilizado de muitas formas e existem diversas formulas de calcula-lo(como será explicado nos proximos tópicos).\n",
        "\n",
        "Lembrando que quanto menor o Loss/perda, melhor o modelo.\n",
        "\n",
        "## Formulas para calculo do Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDToxzrqZCst"
      },
      "source": [
        "## mean squared error (MSE)\n",
        "\n",
        "O erro quadrático médio (MSE) é uma formula utilizada para calcular o erro quadrático de um estimador, levando em consideração o valor estimado e o valor real do exemplo utilizado.\n",
        "\n",
        "Sua formula é a seguinte:\n",
        "\n",
        "* $ MSE = \\frac{1}{n}\\sum (y_{true} - y_{pred})^{2} $\n",
        "\n",
        "Onde:\n",
        "\n",
        "* $ n $ representa o numero de amostras utilizadas\n",
        "* $ y $ representa a variavel que está sendo predizida\n",
        "* $ y_{true} - y_{pred} $ são os valores que representam a amostra, sendo **true** o valor real e **pred** o valor predizido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgmGdQiLZgUz"
      },
      "source": [
        "## Como codar um algoritmo de MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpq76S3oZe55",
        "outputId": "2fe596ef-2890-4c91-9080-9b781a03fd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "  return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "y_true = np.array([1, 0, 0, 1])\n",
        "y_pred = np.array([0, 0, 0, 0])\n",
        "\n",
        "print(mse_loss(y_true, y_pred)) # 0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFg1X-xZRy9"
      },
      "source": [
        "## Sparse Categorical Crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LqvvzLuX9J6"
      },
      "source": [
        "# Treinando uma rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8NyueiLAp8x"
      },
      "source": [
        "## Tipos de treinos de uma rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY-Wg0eNWVb5"
      },
      "source": [
        "# Otimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNfXLT32YEEz"
      },
      "source": [
        "# Tipos de redes neurais\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://mk0iaexpertacadlbryk.kinstacdn.com/wp-content/uploads/2020/06/image-3.png' width=800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5V6VxFlAaep"
      },
      "source": [
        "## Perceptron (P), Feed Forward Network (FFN), Radial Basis Network (RBF)\n",
        "\n",
        "Este tipo de rede neural carateriza os modelos mais basicos que existem, o processo realizado é 100% linear da entrada à saida. Em cada neuronio é realizada uma função matematica linear do tipo $W_x + b$, onde x é o valor de entrada, e W e b são os parametros de peso e bias. \n",
        "\n",
        "O resultado dessa operação pode ou não passar por uma função de ativação antes de partir para a camada adiante.\n",
        "\n",
        "A conexão entre os neuronios representam a passagem de informação de um para o proximo, neuronios que recebem mais de uma entrada, soma elas antes de perfomar a função linear pelo qual é responsavel.\n",
        "\n",
        "* Perceptron -> Modelo mais basico.\n",
        "* Feed Forward Network -> Performa um impacto sintetico dos dados de entrada nos dados de saída.\n",
        "* Radial Basis Network -> Executa funções de ativação com base radial.\n",
        "\n",
        "As NN do tipo FFN e RBF podem conter varias camadas ocultas, sendo comumente chamadas de redes neurais profundas nesse caso. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1FzAzayCxI0"
      },
      "source": [
        "Estas redes neurais são comumente utilizadas para solucionar problemas mais simples e que não demandam um correlacionamento temporal/espacial.\n",
        "\n",
        "Alguns de seus usos são:\n",
        "* Determinar doenças apartir de exames de sangue\n",
        "* Determinar irregularidades em transações simples\n",
        "* Detectar incosistencias em sistemas de armazenamentos\n",
        "* Entre outros..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj3GI_ZYAfDJ"
      },
      "source": [
        "## E como fica o código de uma rede neural dessas?\n",
        "\n",
        "Bom, o código de uma rede neural do tipo FFN ja foi descrito a cima, contudo, segue o mesmo exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp-yYynNJMl5",
        "outputId": "c752dbf0-763e-4bb4-93ae-78f2b38f8b28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class FeedforwardNetwork:\n",
        "\n",
        "  def __init__(self):\n",
        "    weights = np.array([1, 0])\n",
        "    bias = 0\n",
        "\n",
        "    self.n1 = Neuron(weights, bias)\n",
        "    self.n2 = Neuron(weights, bias)\n",
        "    self.o1 = Neuron(weights, bias)\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    out_n1 = self.n1.feedforward(x)\n",
        "    out_n2 = self.n2.feedforward(x)\n",
        "    out_o1 = self.o1.feedforward(np.array([out_n1, out_n2]))\n",
        "\n",
        "    return out_o1\n",
        "\n",
        "network = FeedforwardNetwork()\n",
        "x = np.array([2, 3])\n",
        "print(network.feedforward(x))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7069873680001046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrbdr5r1DZrM"
      },
      "source": [
        "## Rede neural recorrente(RNN)\n",
        "\n",
        "Este modelo de rede neural pode-se de dizer que foi o primeiro a implementar um sistema recorrente no fluxo de dados da rede, dessa forma, os modelos deste modelo são capazes de considerar proprios dados durante o calculo de suas funções matematicas.\n",
        "\n",
        "Além dos dados da camada anterior, os neurônios escondidos da rede neural recorrente utilizam tambem o resultado do seu calculo anterior, realizado no periodo temporal(epoch) anterior.\n",
        "\n",
        "Dessa forma as RNN's são capazes de considerar correlações temporais entre os dados de entrada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k_HNyFGMDKP"
      },
      "source": [
        "Este modelo foi essencial para a avolução das redes neurais e foi amplamente utilizado para descrever modelos que representam dados com fortes correlações temporais.\n",
        "\n",
        "Dessa forma, esse modelo pode ser utilizado para os seguintes propositos:\n",
        "\n",
        "* Previsão do clima baseado em janelas de tempo passadas.\n",
        "* Previsões monatárias ou de ativos baseados em valores históricos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykmIjUx0MdT7"
      },
      "source": [
        "## E como fica o código de uma rede neural dessas?\n",
        "\n",
        "TO-DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiV7zetSMQTb",
        "outputId": "930c572d-a647-4614-ab91-db7642cb8c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class RecurrentNetwork:\n",
        "\n",
        "  def __init__(self):\n",
        "    weights = np.array([1, 0])\n",
        "    bias = 0\n",
        "\n",
        "    self.n1 = Neuron(weights, bias)\n",
        "    self.n2 = Neuron(weights, bias)\n",
        "    self.o1 = Neuron(weights, bias)\n",
        "\n",
        "  def feedforward(self, x, epochs):\n",
        "    out_n1 = self.n1.feedforward(x)\n",
        "    out_n2 = self.n2.feedforward(x)\n",
        "    for _ in np.arange(epochs):\n",
        "      out_n1 = self.n1.feedforward(out_n1)\n",
        "      out_n2 = self.n2.feedforward(out_n2)\n",
        "      print(out_n1, out_n2)\n",
        "\n",
        "    out_o1 = self.o1.feedforward(np.array([out_n1, out_n2]))\n",
        "    return out_o1\n",
        "\n",
        "network = RecurrentNetwork()\n",
        "x = np.array([2, 3])\n",
        "epochs = 5\n",
        "print(network.feedforward(x, epochs))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.70698737 0.5       ] [0.70698737 0.5       ]\n",
            "0.6697351368613155 0.6697351368613155\n",
            "[0.66144385 0.5       ] [0.66144385 0.5       ]\n",
            "0.6595846545654619 0.6595846545654619\n",
            "[0.65916708 0.5       ] [0.65916708 0.5       ]\n",
            "[0.65907326 0.62245933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQAC6Eia4JD1"
      },
      "source": [
        "# Hyperparametros\n",
        "\n",
        "Hyperparametros são os atributos que irão definir a arquitetura(Ex: número de neuronios ocultos) do modelo da sua rede neural, bem como como a sua rede neural irá ser treinada(Ex: taxa de treino), esses paraemtros são definidos antes de iniciar o treinamento do modelo e são de extrema importancia para a perfomance, eficacia e acuracia do modelo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3ws3gvQCQxp"
      },
      "source": [
        "# Principais tipos de Hyperparametros\n",
        "\n",
        "Estes são alguns dos principais hyperparametros que podemos utilziar para trinar alguns modelos de redes neurais, bem como a sua definição e onde podemos utiliza-los."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PyHP3fnCacC"
      },
      "source": [
        "### Nº de camadas ocultas\n",
        "---\n",
        "Este parametro define o numero de camadas ocultas entre a camada de entrada e a camada de saida da sua rede neural, é amplamante utilizada em todas as redes neurais.\n",
        "\n",
        "Basicamente, estas camadas ocultas são utilizadas para melhorar a acuracia do seu modelo, pode-se adicionar novas camadas até que não faça mais diferença se adicionar mais alguma.\n",
        "\n",
        "Varias camadas com boas tecnicas de regularização podem aumentar muito a acuracia do modelo, já se não forem utilizadas ou utilizar poucas, pode acabar gerando um efeito de *underfitting*.\n",
        "\n",
        "*“Very simple. Just keep adding layers until the test error does not improve anymore.”*\n",
        "\n",
        "* Utilizado em: Arquitetura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuCSiC7bENDo"
      },
      "source": [
        "## Dropout\n",
        "---\n",
        "Dropout é um parametro utilizado para evitar *overfitting*, aumentar a acuracia e melhorar o poder de generalização.\n",
        "\n",
        "Geralmente, se utiliza o dropout com valores entre 10% a 50%(porcentagens fazenbdo sempre referencia ao numero de neuronios), 20% pode ser um ponto pra começar a testar a eficacia do parametro. Caso o valor for muito baixo para o tamanho do modelo, o efeito será quase imperceptivel, caso for muito grande, o modelo irá perder poder de aprendizagem.\n",
        "\n",
        "Normalmente o dropout tem mais efeito em redes neurais grandes, dando mais oportunidade da rede neural estabelecer novas representações e conexões.\n",
        "\n",
        "* Utilizado em: Arquitetura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-sOQ1zLadE"
      },
      "source": [
        "## Função de ativação\n",
        "---\n",
        "Como ja explicado anteriormente, as funções de ativação são utilizadas para introduzir elementos de não linearidade ao modelo de rede neural. \n",
        "\n",
        "Para mais informações, consultar \"Função de ativação de uma rede neural\"\n",
        "\n",
        "* Utilizado em: Arquitetura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVZn_lPCM_Iq"
      },
      "source": [
        "## Taxa de aprendizado\n",
        "---\n",
        "A taxa de aprendizado define o quão rapido o modelo irá atualizar seus parametros durante o treinamento, uma baixa taxa de aprendizado pode atrasar o treinamento, contudo, em algum momento irá normalizar. Altas taxas de treinamento pode acelerar o treinamento do modelo, contudo, pode não haver normalização e o modelo não convergir para sua linha natural.\n",
        "\n",
        "Normalmente, se prefere uma taxa de aprendizado decadente.\n",
        "\n",
        "* Utilizado em: Processo de treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZsaM7nNs9l"
      },
      "source": [
        "## Momentum\n",
        "---\n",
        "\n",
        "Este parametro é utilizado para direcionar o aprendizado do modelo de acordo com o resultado da geração de treinamento anterior, ajudando a reduzir oscilações.\n",
        "\n",
        "Normalmente, é preferivel manter este parametro entre 0,5 e 0,9.\n",
        "\n",
        "* Utilizado em: Processo de treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IJ9d9mUT3hz"
      },
      "source": [
        "## Numero de *Epochs*\n",
        "---\n",
        "\n",
        "O numero de *epochs* define o numero de vezes que o dataset de treino irá passar pelo modelo e consequentenmente, quantas vezes o modelo irá treinar utilizando esses dados.\n",
        "\n",
        "Caso o modelo não treine por epocas suficientes, ele não ficará preciso, caso treine por epocas demais, pode ocorrer o efeito de *overfitting*. \n",
        "\n",
        "* Utilizado em: Processo de treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5GsMj76Uce8"
      },
      "source": [
        "## Batch size\n",
        "---\n",
        "\n",
        "O tamanho do *batch* define o tamanho dos subgrupos de dados que serão \"entregues\" ao modelo depois de cada atualização de parametros.\n",
        "\n",
        "Normalmente, o tamanho padrão é definido por multiplos de 32 sendo o tamanho 128 o mais utilizado.\n",
        "\n",
        "* Utilizado em: Processo de treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rNpeGUN0Duq"
      },
      "source": [
        "# Modelo de rede neural generica\n",
        "\n",
        "TO-DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i06Uxb7MBnus"
      },
      "source": [
        "# Exemplos e implementações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98s73XxIZZAn"
      },
      "source": [
        "## MLPClassifier utilizando keras\n",
        "\n",
        "Este exemplo implementa um classificador MLP(Multilayer perceptron), normalmente utilizado para realizar classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uH-mz43ZchP",
        "outputId": "993cc403-5fe5-4ea1-99e3-b836720e3199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "iris_dataset = load_iris()\n",
        "data = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
        "data['target'] = iris_dataset.target\n",
        "\n",
        "validation = data.sample(5)\n",
        "data.drop(validation.index, axis=0, inplace=True)\n",
        "\n",
        "features = data.drop('target', axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, data['target'], random_state=42, test_size=0.25)\n",
        "\n",
        "model = MLPClassifier(max_iter=1000)\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0EkZS0mZf2A",
        "outputId": "e5973128-8ec6-4c37-c9b2-52f901e8e542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample = np.array([5., 2., 3.5, 1.]).reshape(1, -1)\n",
        "flower = model.predict(sample)\n",
        "print(flower[0]) # Iris-Versicolour"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBM0aQiHZ9R6",
        "outputId": "57ece60a-a43c-4083-a882-158951a1323a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_val = validation.drop('target', axis=1)\n",
        "y_val = validation['target']\n",
        "\n",
        "model.score(x_val, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqFeNoQSAvO6"
      },
      "source": [
        "## Rede neural convolucional(Tensorflow) para detecção de tumor cerebral\n",
        "\n",
        "Este modelo de rede neural convolucional é excelente para trabalhar com imagens e categorização das mesmas, amplamente utilizada no mundo médico, como pode ser observado pelo exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loN_eTO1A-3i"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB2_X5yQBHBR"
      },
      "source": [
        "def prepare_data(datadir, img_size=28):\n",
        "\tfile_list = []\n",
        "\tclass_list = []\n",
        "\tx = []\n",
        "\ty = []\n",
        "\tdata = []\n",
        "\terror = False\n",
        "\tcategories = ['NO', 'YES']\n",
        "\n",
        "\tfor category in categories: \n",
        "\t\tpath = os.path.join(datadir, category)\n",
        "\t\tclass_index = categories.index(category)\n",
        "\t\tfor img in os.listdir(path):\n",
        "\t\t\ttry:\n",
        "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\t\t\t\tnew_array = cv2.resize(img_array, (img_size, img_size))\n",
        "\t\t\t\tdata.append([new_array, class_index])\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\terror = True\n",
        "\t\t\t\tpass\n",
        "\n",
        "\trandom.shuffle(data)\n",
        "\n",
        "\tfor features, label in data:\n",
        "\t\tx.append(features)\n",
        "\t\ty.append(label)\n",
        "\n",
        "\tx = np.array(x).reshape(-1, img_size, img_size, 1)\n",
        "\tif error:\n",
        "\t\tprint('Erro ao processar algums imagens')\n",
        "\telse:\n",
        "\t\tprint('Imagens processadas com sucesso')\n",
        "\treturn x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWlehuHz7Zor"
      },
      "source": [
        "x, y = prepare_data('drive/My Drive/Brain/brain-mri-tumor-detection-dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTxu2_7W6wbh"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhrQ7wbs7la6"
      },
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.1, random_state=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-WuI7qL9T8X"
      },
      "source": [
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "y_val = np.array(y_val).reshape(-1, 1)\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "x_val = x_val / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TstXzUg5cOP"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), input_shape = x_train.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# hidden layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(2))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "      optimizer=\"adam\",\n",
        "      metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtUXwM5n5nTR"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWhva_ck-mLQ",
        "outputId": "8da51ab8-63c1-4b91-86e9-0275440821cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"test length \", len(x_test))\n",
        "print(\"test score %.2f%%\" % (np.mean(scores[1] * 100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8676\n",
            "test length  68\n",
            "test score 86.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLJBea_C-jhk",
        "outputId": "e3b77665-06c2-41bb-c5a5-7ea02e794c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "scores = model.evaluate(x_val, y_val)\n",
        "print(\"test length \", len(x_val))\n",
        "print(\"evaluation score %.2f%%\" % (np.mean(scores[1] * 100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7894 - accuracy: 0.8750\n",
            "test length  8\n",
            "evaluation score 87.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp0dbv6W6pUj"
      },
      "source": [
        "def predict_image(file):\n",
        "  img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "  new_array = cv2.resize(img_array, (28, 28))\n",
        "  img = new_array.reshape(-1, 28, 28, 1)\n",
        "  prediction = model.predict([img])\n",
        "  prediction = list(prediction[0])\n",
        "  print(categories[prediction.index(max(prediction))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcuhuOoS-d3Y",
        "outputId": "3800f4e5-9226-4708-f18b-61369daae22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict_image('drive/My Drive/Brain/brain-mri-tumor-detection-dataset/YES/Y21.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "YES\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9V8ZEaqCFlL",
        "outputId": "94354f9a-3679-498f-d904-b09d210270c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict_image('drive/My Drive/Brain/brain-mri-tumor-detection-dataset/NO/N21.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNsuohZB77tb"
      },
      "source": [
        "# Troubleshooting\n",
        "\n",
        "Resolução de alguns dos problemas mais comuns que podem acontecer ao definir e treinar seu modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc1HvFS479x3"
      },
      "source": [
        "## Input 0 is incompatible with layer lstm_xx: expected ndim=3, found ndim=2 in Keras\n",
        "\n",
        "Este problema acontece pois as cadamadas do seu modelo não estão compartilhando o mesmo input/output.\n",
        "\n",
        "Por exemplo, caso você tenha duas camadas LSTM seguidas, onde apenas a primeira tem definida o formato do input e o parametro *return_sequences* não estiver presente, é muito provavel que você tera esse erro, para resolver, apenas passe o parametro *return_sequences* para True, isto fara com que o output da primeira camada esteja de acordo com o input da segunda camada. "
      ]
    }
  ]
}