{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hand_written_digits_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggmdvL_6yKdS",
        "colab_type": "text"
      },
      "source": [
        "# Classificacao de caracteres escritos a mao utilizando CNN\n",
        "\n",
        "Este notebook tem como objetivo praticar a implementacao de um algoritmo de classificacao de imagens utilizando redes neurais convolucionais(CNN), o dataset utilizado sera o MNIST.\n",
        "\n",
        "O objetivo de praticar este metodo e a futura implementacao de um algoritmo de classificacao de raios-x de pulmoes em busca de pneumonia.\n",
        "\n",
        "# Fontes\n",
        "\n",
        "* Artigo: https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/\n",
        "* MNIST: http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "# Autores\n",
        "\n",
        "Victor Bona - https://github.com/vicotrbb\n",
        "\n",
        "\n",
        "# Por que o uso do CNN\n",
        "\n",
        "As redes neurais convolucionais revolucionaram a forma como tratamos o reconhecimento de imagem computacional, trabalha de forma incrivel em tarefas envolvendo visao computacional, classificacao de imagens, deteccaoo de objetos entre outras atividades.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2mmZWsSx4xL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neural network imports\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Accuracy measure imports\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RPldLW6xme4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b39374ad-1aab-4311-829c-048e33c987cc"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reconfigura o conjunto para um vetor de entrada de 28x28 pixels\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Padroniza os dados pra facilitar no treinamento\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# encode utilizando o utilitario do numpy imbutido no keras\n",
        "n_classes = 10\n",
        "print(f'Formato antes do encoding: {y_train.shape}')\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(f'Formato depois do encoding: {y_train.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Formato antes do encoding: (60000,)\n",
            "Formato depois do encoding: (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzuNFcP30VA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constroi a arquitetura da rede neural\n",
        "model = Sequential()\n",
        "# Camada convolucional\n",
        "model.add(Conv2D(25, kernel_size=(3, 3), strides=(1, 1), padding='valid', \n",
        "                 activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPool2D(pool_size=(1, 1)))\n",
        "model.add(Flatten())\n",
        "# Camada oculta\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# Camada de saida\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FKR3o05XoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bd2a05e6-56c8-475e-bb5b-7bbc865f4edd"
      },
      "source": [
        "# Compila o modelo sequencial\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], \n",
        "              optimizer='adam')\n",
        "# Treina o modelo\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, \n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.1875 - accuracy: 0.9462 - val_loss: 0.0715 - val_accuracy: 0.9779\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 39s 652us/step - loss: 0.0592 - accuracy: 0.9825 - val_loss: 0.0530 - val_accuracy: 0.9818\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 39s 648us/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.0491 - val_accuracy: 0.9833\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 39s 650us/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0502 - val_accuracy: 0.9834\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0500 - val_accuracy: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 38s 635us/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0580 - val_accuracy: 0.9828\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 38s 631us/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0677 - val_accuracy: 0.9810\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 38s 636us/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0536 - val_accuracy: 0.9857\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 38s 634us/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0586 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0648 - val_accuracy: 0.9837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f20ed3bfd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zMcjGi6hh2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "14d5e58a-35ff-4a05-a951-c854e6572711"
      },
      "source": [
        "img = Image.open(r\"mnist_test.png\") \n",
        "img = img.resize((28, 28))\n",
        "# convert rgb to grayscale\n",
        "img = img.convert('L')\n",
        "img = np.array(img)\n",
        "# reshaping to support our model input and normalizing\n",
        "img = img.reshape(1, 28, 28, 1)\n",
        "img = img / 255.0\n",
        "# predicting the class\n",
        "res = model.predict([img])[0]\n",
        "print(np.argmax(res))\n",
        "print(max(res) * 100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "96.46003246307373\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}