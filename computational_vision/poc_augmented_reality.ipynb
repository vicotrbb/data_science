{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poc_augmented_reality.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmjMVhtp6vQKG7veWc786y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicotrbb/machine_learning/blob/master/computational_vision/poc_augmented_reality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WTObRQTxMlY",
        "outputId": "fb4bbe2e-9573-475b-ad80-15995239d3b6"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It6KG-Gcym-6"
      },
      "source": [
        "class OBJ:\n",
        "    def __init__(self, filename, swapyz=False):\n",
        "        \"\"\"Loads a Wavefront OBJ file. \"\"\"\n",
        "        self.vertices = []\n",
        "        self.normals = []\n",
        "        self.texcoords = []\n",
        "        self.faces = []\n",
        "        material = None\n",
        "        for line in open(filename, \"r\"):\n",
        "            if line.startswith('#'): continue\n",
        "            values = line.split()\n",
        "            if not values: continue\n",
        "            if values[0] == 'v':\n",
        "                v = list(map(float, values[1:4]))\n",
        "                if swapyz:\n",
        "                    v = v[0], v[2], v[1]\n",
        "                self.vertices.append(v)\n",
        "            elif values[0] == 'vn':\n",
        "                v = list(map(float, values[1:4]))\n",
        "                if swapyz:\n",
        "                    v = v[0], v[2], v[1]\n",
        "                self.normals.append(v)\n",
        "            elif values[0] == 'vt':\n",
        "                self.texcoords.append(map(float, values[1:3]))\n",
        "            elif values[0] == 'f':\n",
        "                face = []\n",
        "                texcoords = []\n",
        "                norms = []\n",
        "                for v in values[1:]:\n",
        "                    w = v.split('/')\n",
        "                    face.append(int(w[0]))\n",
        "                    if len(w) >= 2 and len(w[1]) > 0:\n",
        "                        texcoords.append(int(w[1]))\n",
        "                    else:\n",
        "                        texcoords.append(0)\n",
        "                    if len(w) >= 3 and len(w[2]) > 0:\n",
        "                        norms.append(int(w[2]))\n",
        "                    else:\n",
        "                        norms.append(0)\n",
        "                #self.faces.append((face, norms, texcoords, material))\n",
        "                self.faces.append((face, norms, texcoords))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0IX46BIxp-y"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Minimum number of matches that have to be found\n",
        "# to consider the recognition valid\n",
        "MIN_MATCHES = 10\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    This functions loads the target surface image,\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    homography = None \n",
        "    # matrix of camera parameters (made up but works quite well for me) \n",
        "    camera_parameters = np.array([[640, 0, 352], [0, 640, 352], [0, 0, 1]])\n",
        "    # create ORB keypoint detector\n",
        "    orb = cv2.ORB_create()\n",
        "    # create BFMatcher object based on hamming distance  \n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    # load the reference surface that will be searched in the video stream\n",
        "    dir_name = os.getcwd()\n",
        "    model = cv2.imread('reference.jpeg', 0)\n",
        "    # Compute model keypoints and its descriptors\n",
        "    kp_model, des_model = orb.detectAndCompute(model, None)\n",
        "    # Load 3D model from OBJ file\n",
        "    obj = OBJ('pirate-ship-fat.obj', swapyz=False)  \n",
        "    # init video capture\n",
        "    cap = cv2.VideoCapture('video.mp4')\n",
        "    out = cv2.VideoWriter('out.avi', fourcc, 20.0, (int(cap.get(3)),int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        # read the current frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Unable to capture video, stream ending\")\n",
        "            break\n",
        "        # find and draw the keypoints of the frame\n",
        "        kp_frame, des_frame = orb.detectAndCompute(frame, None)\n",
        "        # match frame descriptors with model descriptors\n",
        "        matches = bf.match(des_model, des_frame)\n",
        "        # sort them in the order of their distance\n",
        "        # the lower the distance, the better the match\n",
        "        matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "        # compute Homography if enough matches are found\n",
        "        if len(matches) > MIN_MATCHES:\n",
        "            # differenciate between source points and destination points\n",
        "            src_pts = np.float32([kp_model[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "            dst_pts = np.float32([kp_frame[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "            # compute Homography\n",
        "            homography, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "            if True:\n",
        "                # Draw a rectangle that marks the found model in the frame\n",
        "                h, w = model.shape\n",
        "                pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "                # project corners into frame\n",
        "                dst = cv2.perspectiveTransform(pts, homography)\n",
        "                # connect them with lines  \n",
        "                frame = cv2.polylines(frame, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
        "            # if a valid homography matrix was found render cube on model plane\n",
        "            if homography is not None:\n",
        "                try:\n",
        "                    projection = projection_matrix(camera_parameters, homography)  \n",
        "                    frame = render(frame, obj, projection, model, False)\n",
        "                    out.write(frame)\n",
        "                    count += 1\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        else:\n",
        "            print (\"Not enough matches found - %d/%d\" % (len(matches), MIN_MATCHES))\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return count\n",
        "\n",
        "def render(img, obj, projection, model, color=False):\n",
        "    \"\"\"\n",
        "    Render a loaded obj model into the current video frame\n",
        "    \"\"\"\n",
        "    vertices = obj.vertices\n",
        "    scale_matrix = np.eye(3) * 3\n",
        "    h, w = model.shape\n",
        "\n",
        "    for face in obj.faces:\n",
        "        face_vertices = face[0]\n",
        "        points = np.array([vertices[vertex - 1] for vertex in face_vertices])\n",
        "        points = np.dot(points, scale_matrix)\n",
        "        # render model in the middle of the reference surface. To do so,\n",
        "        # model points must be displaced\n",
        "        points = np.array([[p[0] + w / 2, p[1] + h / 2, p[2]] for p in points])\n",
        "        dst = cv2.perspectiveTransform(points.reshape(-1, 1, 3), projection)\n",
        "        imgpts = np.int32(dst)\n",
        "        if color is False:\n",
        "            cv2.fillConvexPoly(img, imgpts, (137, 27, 211))\n",
        "        else:\n",
        "            color = hex_to_rgb(face[-1])\n",
        "            color = color[::-1]  # reverse\n",
        "            cv2.fillConvexPoly(img, imgpts, color)\n",
        "\n",
        "    return img\n",
        "\n",
        "def projection_matrix(camera_parameters, homography):\n",
        "    \"\"\"\n",
        "    From the camera calibration matrix and the estimated homography\n",
        "    compute the 3D projection matrix\n",
        "    \"\"\"\n",
        "    # Compute rotation along the x and y axis as well as the translation\n",
        "    homography = homography * (-1)\n",
        "    rot_and_transl = np.dot(np.linalg.inv(camera_parameters), homography)\n",
        "    col_1 = rot_and_transl[:, 0]\n",
        "    col_2 = rot_and_transl[:, 1]\n",
        "    col_3 = rot_and_transl[:, 2]\n",
        "    # normalise vectors\n",
        "    l = math.sqrt(np.linalg.norm(col_1, 2) * np.linalg.norm(col_2, 2))\n",
        "    rot_1 = col_1 / l\n",
        "    rot_2 = col_2 / l\n",
        "    translation = col_3 / l\n",
        "    # compute the orthonormal basis\n",
        "    c = rot_1 + rot_2\n",
        "    p = np.cross(rot_1, rot_2)\n",
        "    d = np.cross(c, p)\n",
        "    rot_1 = np.dot(c / np.linalg.norm(c, 2) + d / np.linalg.norm(d, 2), 1 / math.sqrt(2))\n",
        "    rot_2 = np.dot(c / np.linalg.norm(c, 2) - d / np.linalg.norm(d, 2), 1 / math.sqrt(2))\n",
        "    rot_3 = np.cross(rot_1, rot_2)\n",
        "    # finally, compute the 3D projection matrix from the model to the current frame\n",
        "    projection = np.stack((rot_1, rot_2, rot_3, translation)).T\n",
        "    return np.dot(camera_parameters, projection)\n",
        "\n",
        "def hex_to_rgb(hex_color):\n",
        "    \"\"\"\n",
        "    Helper function to convert hex strings to RGB\n",
        "    \"\"\"\n",
        "    hex_color = hex_color.lstrip('#')\n",
        "    h_len = len(hex_color)\n",
        "    return tuple(int(hex_color[i:i + h_len // 3], 16) for i in range(0, h_len, h_len // 3))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXnTO5G20OhW",
        "outputId": "21eaae63-9575-4823-fd62-4c1c2a3c1fd7"
      },
      "source": [
        "main()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unable to capture video, stream ending\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}